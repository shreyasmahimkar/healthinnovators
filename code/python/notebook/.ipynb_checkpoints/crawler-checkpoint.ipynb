{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get Linkedin access\n",
    "username = \"\"\n",
    "password = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib2\n",
    "import cookielib\n",
    "import re\n",
    "import os\n",
    "\n",
    "import string\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "\n",
    "cookie_filename = \"parser.cookies3.txt\"\n",
    "\n",
    "class LinkedInParser(object):\n",
    "\n",
    "    def __init__(self, login, password):\n",
    "        print \"\"\" Start up... \"\"\"\n",
    "        self.login = login\n",
    "        self.password = password\n",
    "\n",
    "        # Simulate browser with cookies enabled\n",
    "        self.cj = cookielib.MozillaCookieJar(cookie_filename)\n",
    "        if os.access(cookie_filename, os.F_OK):\n",
    "            self.cj.load()\n",
    "        self.opener = urllib2.build_opener(\n",
    "            urllib2.HTTPRedirectHandler(),\n",
    "            urllib2.HTTPHandler(debuglevel=0),\n",
    "            urllib2.HTTPSHandler(debuglevel=0),\n",
    "            urllib2.HTTPCookieProcessor(self.cj)\n",
    "        )\n",
    "        self.opener.addheaders = [\n",
    "            ('User-agent', ('Mozilla/4.0 (compatible; MSIE 6.0; '\n",
    "                           'Windows NT 5.2; .NET CLR 1.1.4322)'))\n",
    "        ]\n",
    "\n",
    "        # Login\n",
    "        self.loginPage()\n",
    "\n",
    "        title = self.loadTitle()\n",
    "        print title\n",
    "\n",
    "        self.cj.save()\n",
    "\n",
    "\n",
    "    def loadPage(self, url, data=None):\n",
    "        \"\"\"\n",
    "        Utility function to load HTML from URLs for us with hack to continue despite 404\n",
    "        \"\"\"\n",
    "        # We'll print the url in case of infinite loop\n",
    "        # print \"Loading URL: %s\" % url\n",
    "        try:\n",
    "            if data is not None:\n",
    "                response = self.opener.open(url, data)\n",
    "            else:\n",
    "                response = self.opener.open(url)\n",
    "            return ''.join(response.readlines())\n",
    "        except:\n",
    "            # If URL doesn't load for ANY reason, try again...\n",
    "            # Quick and dirty solution for 404 returns because of network problems\n",
    "            # However, this could infinite loop if there's an actual problem\n",
    "            return self.loadPage(url, data)\n",
    "\n",
    "    def loginPage(self):\n",
    "        \"\"\"\n",
    "        Handle login. This should populate our cookie jar.\n",
    "        \"\"\"\n",
    "        html = self.loadPage(\"https://www.linkedin.com/\")\n",
    "        soup = BeautifulSoup(html)\n",
    "        csrf = soup.find(id=\"loginCsrfParam-login\")['value']\n",
    "\n",
    "        login_data = urllib.urlencode({\n",
    "            'session_key': self.login,\n",
    "            'session_password': self.password,\n",
    "            'loginCsrfParam': csrf,\n",
    "        })\n",
    "\n",
    "        html = self.loadPage(\"https://www.linkedin.com/uas/login-submit\", login_data)\n",
    "        return\n",
    "\n",
    "    def loadTitle(self):\n",
    "        html = self.loadPage(\"http://www.linkedin.com/nhome\")\n",
    "        soup = BeautifulSoup(html)\n",
    "        print \"Login into \" + str(username) +\" successfull\"\n",
    "        return soup.find(\"title\")\n",
    "\n",
    "parser = LinkedInParser(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 1\n",
    "\n",
    "#Loading Health Innovators Page which has followers. \n",
    "pageLoad = parser.loadPage(\"https://www.linkedin.com/company/health-innovators/followers?trk=extra_biz_followers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Step2\n",
    "# This wrapper parses the html is a very good readable format\n",
    "soup = BeautifulSoup(pageLoad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 3\n",
    "# Go to the Linked link above using LinkedIn credentials and see if you can find the users in the below print statement.\n",
    "print soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4\n",
    "# In this block Extract the LinkedIn link to User's and open using \n",
    "pageLoaduser = parser.loadPage(\"Link to the user profile\") # This will be the user's LinkedIn Profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 5\n",
    "# Extract First Name, Last Name, Contact Information , etc. as given in the Health Innovators document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 6\n",
    "# Repeat Step 4 and 5 for all the Followers on the Health Innovators Page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
